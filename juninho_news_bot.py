import html
import logging
import os
import random
import time
import json
from datetime import datetime, timedelta

import ephem
import pandas as pd
import pytz
import requests
from bs4 import BeautifulSoup # lxml precisar√° estar instalado para 'xml' parser

# --- Configura√ß√£o b√°sica de logging ---
# Para debug mais detalhado, pode mudar para logging.DEBUG
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - [%(funcName)s:%(lineno)d] - %(message)s')

# --- Constantes Globais ---
NEWS_API_URL = "https://newsapi.org/v2/everything"
COINGECKO_API_URL = "https://api.coingecko.com/api/v3/simple/price"
BIBLE_GATEWAY_VOTD_URL = "https://www.biblegateway.com/votd/get/?format=xml&version=ARC"
PENSADOR_URL = "https://www.pensador.com/frases_de_pensadores_famosos/"
BOATOS_ORG_FEED_URL = "https://www.boatos.org/feed"
EXCHANGE_RATE_API_BASE_URL = "https://v6.exchangerate-api.com/v6"

USER_AGENT = "JuninhoNewsBot/1.12 (Automated Script)"
FUSO_BRASIL = pytz.timezone('America/Sao_Paulo')
FILE_PATH_DATAS_COMEMORATIVAS = "datas comemorativas.xlsx" # Assume que est√° na raiz do projeto

# --- Carregar Segredos das Vari√°veis de Ambiente ---
NEWS_API_KEY = os.getenv('NEWS_API_KEY')
EXCHANGE_RATE_API_KEY = os.getenv('EXCHANGE_RATE_API_KEY')
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

# --- Fun√ß√µes Utilit√°rias e de Busca ---

def safe_request_get(url, params=None, timeout=10, max_retries=2, delay_seconds=2):
    headers = {'User-Agent': USER_AGENT}
    # Evitar cache excessivo para fontes que atualizam frequentemente
    if not ("newsapi.org" in url and NEWS_API_KEY) and not ("api.coingecko.com" in url):
        headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        headers['Pragma'] = 'no-cache'
        headers['Expires'] = '0'

    for attempt in range(max_retries):
        try:
            time.sleep(random.uniform(0.5, 1.5)) # Pausa entre tentativas/requisi√ß√µes
            response = requests.get(url, params=params, headers=headers, timeout=timeout)
            response.raise_for_status() # Levanta erro para status 4xx/5xx
            return response
        except requests.exceptions.HTTPError as http_err:
            logging.error(f"HTTP error: {http_err} (URL: {url}, Status: {http_err.response.status_code})")
            if http_err.response.status_code in [401, 403]: # N√£o autorizado ou Proibido
                logging.error("Erro de autoriza√ß√£o/permiss√£o. Verifique chaves de API ou acesso.")
                break 
            if http_err.response.status_code == 429: # Too Many Requests
                logging.warning(f"Rate limit atingido para {url}. Aguardando {delay_seconds * (attempt + 2)}s.")
                time.sleep(delay_seconds * (attempt + 2)) 
        except requests.exceptions.ConnectionError as conn_err:
            logging.error(f"Connection error: {conn_err} (URL: {url})")
        except requests.exceptions.Timeout as timeout_err:
            logging.error(f"Timeout error: {timeout_err} (URL: {url})")
        except requests.exceptions.RequestException as req_err: # Erro gen√©rico da requests
            logging.error(f"General request error: {req_err} (URL: {url})")
        
        if attempt < max_retries - 1:
            logging.info(f"Tentando novamente {url} em {delay_seconds}s... (Tentativa {attempt + 1}/{max_retries})")
            time.sleep(delay_seconds)
        else:
            logging.error(f"M√°ximo de tentativas ({max_retries}) atingido para {url}.")
            break
    return None

def get_saudacao() -> str:
    """Retorna uma sauda√ß√£o baseada na hora atual."""
    hora_atual = datetime.now(FUSO_BRASIL).hour
    if 5 <= hora_atual < 12:
        return "Bom dia!"
    elif 12 <= hora_atual < 18:
        return "Boa tarde!"
    else:
        return "Boa noite!"

def fase_da_lua(data_str_ephem_format: str) -> str:
    try:
        date_observer = ephem.Date(data_str_ephem_format)
        moon = ephem.Moon(date_observer)
        illumination = moon.phase 
        
        prev_date = ephem.Date(date_observer - 1)
        moon_prev = ephem.Moon(prev_date)
        is_waxing = illumination > moon_prev.phase
        
        if abs(illumination - moon_prev.phase) < 0.5 : 
            pnm = ephem.previous_new_moon(date_observer)
            pfm = ephem.previous_full_moon(date_observer)
            if date_observer == pnm or date_observer == ephem.next_new_moon(date_observer): illumination = 0
            if date_observer == pfm or date_observer == ephem.next_full_moon(date_observer): illumination = 50 
            is_waxing = True if pnm > pfm and date_observer > pnm else (False if pfm > pnm and date_observer > pfm else is_waxing)

        if illumination < 3: return "Lua Nova üåë"
        if illumination > 97: return "Lua Nova (final) üåë" 
        if illumination >= 48 and illumination <= 52: return "Lua Cheia üåï"
        if illumination >= 23 and illumination <= 27:
            return "Quarto Crescente üåì" if is_waxing else "Quarto Minguante üåó"
        if is_waxing:
            if illumination < 23: return "Lua Crescente C√¥ncava üåí"
            if illumination < 48: return "Lua Crescente Gibosa üåî"
        else: 
            if illumination > 77: return "Lua Minguante C√¥ncava üåò"
            if illumination > 52: return "Lua Minguante Gibosa üåñ"
        logging.warning(f"Fase da lua (ilum: {illumination}%, crescendo: {is_waxing}) n√£o encaixou, usando fallback.")
        return "Fase Crescente (aprox.) üåî" if is_waxing else "Fase Minguante (aprox.) üåñ"
    except Exception as e:
        logging.exception(f"Erro ao calcular fase da lua para '{data_str_ephem_format}': {e}")
        return "Fase da lua indispon√≠vel"

def obter_datas_comemorativas(file_path: str, sheet_name='tabela') -> str:
    logging.info(f"Tentando ler arquivo de datas comemorativas de: {file_path}")
    # No GitHub Actions, o diret√≥rio de trabalho √© a raiz do reposit√≥rio.
    # Vamos verificar o caminho absoluto para ter certeza.
    abs_file_path = os.path.abspath(file_path)
    logging.info(f"Caminho absoluto resolvido para: {abs_file_path}")
    logging.info(f"Arquivo existe em '{abs_file_path}'? {os.path.exists(abs_file_path)}")

    try:
        if not os.path.exists(abs_file_path): # Usa o caminho absoluto para a verifica√ß√£o
            return "‚ö†Ô∏è Arquivo de datas comemorativas n√£o encontrado no caminho esperado."
        
        df = pd.read_excel(abs_file_path, sheet_name=sheet_name)
        if df.empty or len(df.columns) < 2:
            logging.warning(f"Arquivo de datas '{abs_file_path}' est√° vazio ou com formato incorreto.")
            return "‚ö†Ô∏è Arquivo de datas vazio ou mal formatado."
        
        # Assume que a primeira coluna √© data e a segunda √© descri√ß√£o
        df.columns = ['DataRaw', 'DescricaoRaw'] + list(df.columns[2:])
        df['Data'] = pd.to_datetime(df['DataRaw'], errors='coerce')
        df['Descricao'] = df['DescricaoRaw'].astype(str).str.strip()
        
        data_atual_obj = datetime.now(FUSO_BRASIL).date()
        datas_hoje = df[df['Data'].dt.date == data_atual_obj]
        
        if not datas_hoje.empty:
            return "\n".join(f"- {row['Descricao']}" for _, row in datas_hoje.iterrows())
        return f"Nenhuma data comemorativa listada para hoje ({data_atual_obj.strftime('%d/%m')})."
    except FileNotFoundError: # Embora os.path.exists deva pegar isso, √© uma boa pr√°tica.
        logging.error(f"FileNotFoundError ao tentar ler: {abs_file_path}")
        return "‚ö†Ô∏è Arquivo de datas comemorativas n√£o encontrado (FileNotFoundError)."
    except Exception as e:
        logging.exception(f"Erro ao ler/processar datas comemorativas de '{abs_file_path}': {e}")
        return "‚ö†Ô∏è Erro ao carregar datas comemorativas."

def get_crypto_price(coin_id: str, coin_name: str) -> float | None:
    url = f"{COINGECKO_API_URL}?ids={coin_id}&vs_currencies=brl"
    response = safe_request_get(url)
    if response:
        try:
            data = response.json()
            price = data.get(coin_id, {}).get("brl")
            if price is not None: return float(price)
        except (ValueError, TypeError, AttributeError, requests.exceptions.JSONDecodeError) as e:
            logging.exception(f"Erro ao processar dados de {coin_name} da CoinGecko: {e}")
    return None

def get_biblical_verse() -> str:
    response = safe_request_get(BIBLE_GATEWAY_VOTD_URL)
    if response:
        try:
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'xml') # Requer lxml
            verse_text_tag, reference_tag = soup.find("text"), soup.find("reference")
            if verse_text_tag and reference_tag:
                return f"{html.unescape(verse_text_tag.text.strip())} ({html.unescape(reference_tag.text.strip())})"
        except Exception as e: logging.exception(f"Erro ao processar XML da Bible Gateway: {e}")
    return "N√£o foi poss√≠vel obter o vers√≠culo."

def get_quote_pensador() -> str:
    response = safe_request_get(PENSADOR_URL)
    if response:
        try:
            soup = BeautifulSoup(response.text, "html.parser")
            frases_tags = soup.select("p.frase") # Seletor pode mudar com o tempo
            if frases_tags:
                frase_el = random.choice(frases_tags)
                texto_frase = frase_el.text.strip()
                autor = None
                autor_el_p = frase_el.find_next_sibling("p", class_="autor")
                if autor_el_p and autor_el_p.find('a'): autor = autor_el_p.find('a').text.strip()
                if not autor : 
                    autor_el_span = frase_el.find_parent().find("span", class_="autor")
                    if autor_el_span : autor = autor_el_span.text.strip()
                return f'"{texto_frase}"{f" - {autor}" if autor else ""}'
        except Exception as e: logging.exception(f"Erro ao processar HTML do Pensador.com: {e}")
    return "‚ö†Ô∏è Nenhuma frase encontrada."

def get_boatos_org_feed() -> dict | str :
    response = safe_request_get(BOATOS_ORG_FEED_URL)
    if response:
        try:
            soup = BeautifulSoup(response.content, 'xml') # Requer lxml
            items = soup.find_all("item")
            if items:
                boato = random.choice(items)
                titulo_tag, link_tag = boato.find("title"), boato.find("link")
                if titulo_tag and link_tag:
                    return {"title": titulo_tag.text.strip(), "link": link_tag.text.strip()}
                return "‚ö†Ô∏è Formato inesperado no feed Boatos.org."
        except Exception as e:
            logging.exception(f"Erro ao processar feed RSS do Boatos.org: {e}")
            if "Couldn't find a tree builder" in str(e): # Erro espec√≠fico se lxml n√£o estiver instalado
                return "‚ùå Erro: Parser XML (lxml) n√£o encontrado."
    return "‚ùå Erro ao buscar fake news do Boatos.org."

def get_exchange_rate_api(base_currency: str, target_currency: str, api_key: str | None) -> str:
    if api_key:
        url = f"{EXCHANGE_RATE_API_BASE_URL}/{api_key}/latest/{base_currency}"
        response = safe_request_get(url)
        if response:
            try:
                data = response.json()
                if data.get("result") == "success":
                    rate = data.get("conversion_rates", {}).get(target_currency)
                    if rate: return f"{rate:,.2f}"
                    return f"Erro API ({target_currency}?)"
                return "Erro API Cota√ß√£o"
            except (requests.exceptions.JSONDecodeError, Exception) as e:
                logging.exception(f"Erro com ExchangeRate-API: {e}")
                return "Erro API (Proc.)"
        return "Falha Conex√£o API Cota√ß√£o"
    return "Indispon√≠vel (API √±/config.)"

def buscar_noticias_newsapi(query_term: str, max_articles: int = 5) -> tuple[list[dict], str | None]:
    if not NEWS_API_KEY: return [], "‚ö†Ô∏è Chave API NewsAPI n√£o configurada."
    parametros = {'q': query_term, 'language': 'pt', 'sortBy': 'publishedAt', 'pageSize': max_articles + 10, 'apiKey': NEWS_API_KEY}
    response = safe_request_get(NEWS_API_URL, params=parametros)
    if not response: return [], f"‚ùå Falha NewsAPI para '{query_term}'."
    try: dados = response.json()
    except requests.exceptions.JSONDecodeError:
        logging.error(f"Erro JSON NewsAPI '{query_term}'. Conte√∫do: {response.text[:200]}")
        return [], "‚ùå Erro NewsAPI (JSON)."
    articles_data = []
    if dados.get('status') == 'ok' and dados.get('totalResults', 0) > 0:
        titulos_exibidos = set()
        for art_api in dados.get('articles', []):
            titulo = art_api.get('title')
            if not titulo or "[Removed]" in titulo or titulo in titulos_exibidos: continue
            titulos_exibidos.add(titulo)
            desc = art_api.get('description', "") 
            if len(desc) > 150: desc = desc[:147].strip() + "..."
            articles_data.append({"title": titulo, "source": art_api.get('source', {}).get('name', 'N/A'), "description": desc, "url": art_api.get('url')})
            if len(articles_data) >= max_articles: break
        if not articles_data: return [], f"Nenhuma not√≠cia relevante para '{query_term}' (p√≥s-filtros)."
        return articles_data, None
    elif dados.get('status') == 'error':
        msg = f"‚ö†Ô∏è Erro NewsAPI ({dados.get('code', 'err')}): {dados.get('message', '')}"
        return [], msg
    return [], f"Nenhuma not√≠cia sobre '{query_term}'."

# --- Fun√ß√µes do Telegram ---

def escape_markdown_v2(text: str | None) -> str:
    if text is None: text = ""
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    res = []
    for char in text:
        if char in escape_chars: res.append(f'\\{char}')
        else: res.append(char)
    return "".join(res)

def formatar_para_telegram_plain(jornal_data: dict) -> str:
    plain_list = []
    data_display = jornal_data["data_display"]
    fase_lua = jornal_data["fase_lua"]
    
    plain_list.append(f"*{escape_markdown_v2(jornal_data['saudacao'])}*") # Sauda√ß√£o
    plain_list.append(f"üì∞ *{escape_markdown_v2(f'Juninho News - {data_display}')}*")
    plain_list.append(f"üìå _{escape_markdown_v2('De Pires do Rio-GO')}_")
    plain_list.append(f"üåí _{escape_markdown_v2(fase_lua)}_")
    plain_list.append("")

    plain_list.append(f"üí≠ *{escape_markdown_v2('Frase de Hoje')}*")
    plain_list.append(f"_{escape_markdown_v2(jornal_data['frase_dia'])}_")
    plain_list.append("")
    plain_list.append(f"üìñ *{escape_markdown_v2('Vers√≠culo do Dia')}*")
    plain_list.append(f"_{escape_markdown_v2(jornal_data['versiculo_dia'])}_")
    plain_list.append(f"_{escape_markdown_v2('Fonte: Bible Gateway (ARC)')}_")
    plain_list.append("") 

    plain_list.append(f"üôè *{escape_markdown_v2('Agradecemos por acompanhar nosso jornal')}*")
    plain_list.append(escape_markdown_v2("!Se gostou do conte√∫do e quer apoiar nosso trabalho, qualquer contribui√ß√£o via Pix √© muito bem-vinda! üíô"))
    plain_list.append(f"üìå *{escape_markdown_v2('Chave Pix:')}* `{escape_markdown_v2('64992115946')}`")
    plain_list.append(escape_markdown_v2("Seu apoio nos ajuda a continuar trazendo informa√ß√µes com qualidade e dedica√ß√£o. Obrigado! üòä"))
    plain_list.append("")

    plain_list.append(f"üóì *{escape_markdown_v2(f'HOJE √â DIA... {data_display}:')}*")
    # A fun√ß√£o obter_datas_comemorativas retorna plain text, escapamos aqui para seguran√ßa com MarkdownV2
    datas_comemorativas_linhas = [escape_markdown_v2(line) for line in jornal_data['datas_comemorativas'].splitlines()]
    plain_list.append("\n".join(datas_comemorativas_linhas))
    plain_list.append("")
    
    plain_list.append(f"üíπ *{escape_markdown_v2('Cota√ß√µes')}*")
    plain_list.append(f" üíµ {escape_markdown_v2('Cota√ß√£o do D√≥lar')}")
    plain_list.append(f" {escape_markdown_v2(f'R$ {jornal_data["cotacoes"]["dolar"]}')}")
    plain_list.append("")
    plain_list.append(f"üí∂ {escape_markdown_v2('Cota√ß√£o do Euro')}")
    plain_list.append(f" {escape_markdown_v2(f'R$ {jornal_data["cotacoes"]["euro"]}')}")
    plain_list.append("")
    plain_list.append(f"ü™ô {escape_markdown_v2('Cota√ß√£o do Ethereum')}")
    plain_list.append(f" {escape_markdown_v2(f"R${jornal_data['cotacoes']['eth_plain_str']}")}")
    plain_list.append("")
    plain_list.append(f"ü™ô {escape_markdown_v2('Cota√ß√£o do Bitcoin')}")
    plain_list.append(f" {escape_markdown_v2(f"R$ {jornal_data['cotacoes']['btc_plain_str']}")}")
    plain_list.append(f"_{escape_markdown_v2('Cripto: Dados por CoinGecko')}_")
    plain_list.append("")

    for secao_titulo_com_emoji, artigos_ou_msg in jornal_data['noticias'].items():
        plain_list.append(f"\n*{escape_markdown_v2(secao_titulo_com_emoji)}*") 
        nome_secao_limpo = secao_titulo_com_emoji
        for emoji_char in "üáßüá∑üü¢üåçüåê‚öΩüí∞üçÄüåü‚úàÔ∏èüèÜüíª": nome_secao_limpo = nome_secao_limpo.replace(emoji_char, "")
        nome_secao_limpo = nome_secao_limpo.replace("(", "").replace(")", "").replace("&", "e").replace("Estado", "").strip()
        
        sub_titulo_texto = ""
        if "Geopolitica" in nome_secao_limpo: sub_titulo_texto = f"√öltimas not√≠cias da Geopol√≠tica mundial:"
        elif "INTERNACIONAL" in secao_titulo_com_emoji: sub_titulo_texto = "√öltimas not√≠cias internacionais e do mundo:"
        else: sub_titulo_texto = f"√öltimas not√≠cias de {nome_secao_limpo}:"
        plain_list.append(f"üì¢ {escape_markdown_v2(sub_titulo_texto)}\n")
            
        if isinstance(artigos_ou_msg, str):
            plain_list.append(escape_markdown_v2(artigos_ou_msg))
        else:
            for artigo in artigos_ou_msg:
                escaped_title = escape_markdown_v2(artigo['title'])
                if artigo['url']:
                    plain_list.append(f"üì∞ [{escaped_title}]({artigo['url']})") 
                else:
                    plain_list.append(f"üì∞ {escaped_title}")
                plain_list.append(f"üè∑ _{escape_markdown_v2('Fonte:')} {escape_markdown_v2(artigo['source'])}_")
                if artigo['description']:
                    desc_limpa = artigo['description'].replace('\r\n', '\n').replace('\r', '\n')
                    plain_list.append(f"üìù _{escape_markdown_v2(desc_limpa)}_")
                plain_list.append("") 
        plain_list.append("") 
    
    plain_list.append(f"üîé *{escape_markdown_v2('#FAKENEWS')}*") 
    boato_data = jornal_data['fake_news']
    if isinstance(boato_data, dict):
        plain_list.append(f"üõë _{escape_markdown_v2('Fake News desmentida:')}_")
        escaped_boato_title = escape_markdown_v2(boato_data['title'])
        plain_list.append(f"üì¢ [{escaped_boato_title}]({boato_data['link']})")
    else: 
        plain_list.append(escape_markdown_v2(boato_data))
    plain_list.append(f"_{escape_markdown_v2('Fonte: Boatos.org (Feed RSS)')}_")
    plain_list.append("")
    
    return "\n".join(plain_list)

def send_telegram_message(bot_token: str, chat_id: str, message_text: str):
    if not bot_token or not chat_id:
        logging.error("Token do Bot ou Chat ID do Telegram n√£o fornecidos.")
        return False
    send_url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    max_length = 4096
    messages_to_send = []

    # L√≥gica de divis√£o de mensagens aprimorada
    if len(message_text) > max_length:
        logging.warning(f"Mensagem ({len(message_text)} caracteres) excede limite. Ser√° dividida.")
        current_part = ""
        # Tenta dividir por blocos de not√≠cias (identificados por "---" ou linhas em branco duplas)
        # ou por se√ß√µes principais.
        # Uma abordagem mais simples √© dividir por linhas, mas tentando manter blocos.
        
        # Separador usado na formata√ß√£o
        block_separator = escape_markdown_v2("\n--------------------\n") # Se usar este como separador principal
        if not block_separator.strip(): # Fallback se o separador for apenas newlines
            block_separator = "\n\n\n" # Tenta por 3 newlines (2 em branco)

        parts = message_text.split(block_separator)
        temp_messages = []
        current_message_block = ""

        for i, part_content in enumerate(parts):
            # Adiciona o separador de volta, exceto para o √∫ltimo
            part_with_separator = part_content + (block_separator if i < len(parts) -1 else "")
            
            if len(current_message_block) + len(part_with_separator) <= max_length:
                current_message_block += part_with_separator
            else:
                # Se o bloco atual j√° tem algo, envia
                if current_message_block:
                    temp_messages.append(current_message_block)
                # Come√ßa um novo bloco. Se o pr√≥prio part_with_separator for muito grande,
                # ele ser√° tratado na pr√≥xima etapa de truncamento.
                current_message_block = part_with_separator
        
        if current_message_block: # Adiciona o √∫ltimo bloco
            temp_messages.append(current_message_block)

        # Se alguma parte ainda for muito longa, trunca
        for part_msg in temp_messages:
            if len(part_msg) > max_length:
                logging.warning(f"Sub-parte da mensagem ({len(part_msg)} caracteres) ainda excede o limite. Ser√° truncada.")
                messages_to_send.append(part_msg[:max_length - 30] + "\n" + escape_markdown_v2("...[mensagem cortada]..."))
            elif part_msg.strip(): # Adiciona apenas se n√£o estiver vazia
                 messages_to_send.append(part_msg)

        if not messages_to_send and message_text: 
             messages_to_send.append(message_text[:max_length - 30] + "\n" + escape_markdown_v2("...[mensagem cortada]..."))
    else:
        messages_to_send.append(message_text)

    all_sent_successfully = True
    for i, part_message in enumerate(messages_to_send):
        if not part_message.strip(): continue
        payload = {'chat_id': chat_id, 'text': part_message, 
                   'parse_mode': 'MarkdownV2', 
                   'disable_web_page_preview': False}
        try:
            response = requests.post(send_url, data=payload, timeout=30)
            response_json = {}
            try: response_json = response.json()
            except json.JSONDecodeError: logging.error(f"Resp Telegram n√£o JSON. Status: {response.status_code}, Resp: {response.text[:200]}")
            if response.status_code == 200 and response_json.get("ok"):
                logging.info(f"Parte {i+1}/{len(messages_to_send)} enviada ao Telegram (Chat ID: {chat_id}).")
            else:
                logging.error(f"Falha envio parte {i+1} Telegram. Status: {response.status_code}, Resp: {response.text}")
                all_sent_successfully = False
            time.sleep(2) 
        except requests.exceptions.RequestException as e:
            logging.exception(f"Exce√ß√£o envio parte {i+1} Telegram: {e}")
            all_sent_successfully = False
    return all_sent_successfully

# --- Fun√ß√£o Principal Adaptada para Automa√ß√£o ---
def main_automated():
    logging.info("Iniciando execu√ß√£o do Juninho News Automatizado.")
    if not all([NEWS_API_KEY, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID]):
        logging.critical("ERRO CR√çTICO: Vari√°veis de ambiente essenciais n√£o configuradas!")
        return

    current_time_obj = datetime.now(FUSO_BRASIL)
    eth_val, btc_val = get_crypto_price('ethereum', 'Ethereum'), get_crypto_price('bitcoin', 'Bitcoin')

    jornal_data = {
        'saudacao': get_saudacao(), # Adicionada sauda√ß√£o
        'data_display': current_time_obj.strftime('%d/%m/%Y'),
        'fase_lua': fase_da_lua(current_time_obj.strftime('%Y/%m/%d')),
        'frase_dia': get_quote_pensador(),
        'versiculo_dia': get_biblical_verse(),
        'datas_comemorativas': obter_datas_comemorativas(FILE_PATH_DATAS_COMEMORATIVAS),
        'cotacoes': {
            'dolar': get_exchange_rate_api("USD", "BRL", EXCHANGE_RATE_API_KEY),
            'euro': get_exchange_rate_api("EUR", "BRL", EXCHANGE_RATE_API_KEY),
            'eth_plain_str': f"{eth_val:,.2f}" if eth_val is not None else "Erro/Indispon√≠vel",
            'btc_plain_str': f"{btc_val:,.2f}" if btc_val is not None else "Erro/Indispon√≠vel",
        },
        'noticias': {},
        'fake_news': get_boatos_org_feed()
    }

    news_sections_queries = {
        "üáßüá∑ BRASIL GERAL": "Brasil", 
        "üü¢ Goi√°s (Estado)": f"Goi√°s OR \"Estado de Goi√°s\" NOT \"Goi√°s Esporte Clube\"",
        "üåç Geopol√≠tica": "Geopol√≠tica OR \"Rela√ß√µes Internacionais\"", 
        "üåê INTERNACIONAL": "Internacional OR Mundial NOT Brasil",
        "‚öΩ Futebol": "Futebol Brasil OR \"Campeonato Brasileiro\" OR Libertadores OR \"Copa do Brasil\"",
        "üí∞ ECONOMIA & NEG√ìCIOS": "\"Economia Brasileira\" OR Infla√ß√£o OR Selic OR IBGE OR BCB", 
        "üçÄ LOTERIAS": "\"Loterias Caixa\" OR Mega-Sena OR Quina OR Lotof√°cil",
        "üåü FAMA & ENTRETENIMENTO": "Celebridades OR Entretenimento OR Famosos Brasil", 
        "‚úàÔ∏è TURISMO": "Turismo Brasil OR Viagens OR \"Pontos Tur√≠sticos\"", 
        "üèÜ ESPORTES": "Esportes Brasil -futebol NOT \"e-sports\"",
        "üíª Tecnologia": "Tecnologia OR Inova√ß√£o OR Intelig√™ncia Artificial OR Startups Brasil"
    }

    for titulo_secao_com_emoji, query in news_sections_queries.items():
        artigos, msg_erro = buscar_noticias_newsapi(query, max_articles=5)
        if msg_erro and not artigos: jornal_data['noticias'][titulo_secao_com_emoji] = msg_erro
        elif not artigos and not msg_erro: jornal_data['noticias'][titulo_secao_com_emoji] = f"Nenhuma not√≠cia relevante para '{query}'."
        else: jornal_data['noticias'][titulo_secao_com_emoji] = artigos

    telegram_message_text = formatar_para_telegram_plain(jornal_data)
    
    # print(telegram_message_text) # Descomente para debug local

    if not send_telegram_message(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, telegram_message_text):
        logging.error("Falha CR√çTICA ao enviar a mensagem completa para o Telegram.")
    else:
        logging.info("Juninho News enviado com sucesso para o Telegram!")

# --- Bloco de Execu√ß√£o Principal ---
if __name__ == "__main__":
    main_automated()
